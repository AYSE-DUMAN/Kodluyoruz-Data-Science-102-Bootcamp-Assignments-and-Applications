{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evrişimsel Sinir Ağı Oluşturma "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Adım: Veri Kümesini Yükleme\n",
    "2. Adım: Veri Kümesini Tekrarlanabilir Yapıya Dönüştürme\n",
    "3. Adım: Model Sınıfı Oluşturma\n",
    "4. Adım: Model Sınıfını Oluşturma\n",
    "5. Adım: Loss Sınıfını Oluşturma\n",
    "6. Adım: Optimizer Sınıfını Oluşturma\n",
    "7. Adım: Modelin Eğitilmesi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu çalışmamda Evrişimsel Sinir Ağını 2 tane Convolutional Layer, 2 tane Max Pooling Layer ve 1 tane Fully Connectted Layer ile oluşturdum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adım 1: MNIST Veri Kümesini Yükleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.train_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.train_labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.test_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.test_labels.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Adım: Veri Kümesini Tekrarlanabilir Yapıya Dönüştürme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = int(n_iters/(len(train_dataset) / batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size= batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size= batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adım: Model Sınıfı Oluşturma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        \n",
    "        # Comvolutaion Layer 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size = 5, stride = 1, padding = 2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # Max Pooling Layer 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Comvolutaion Layer 2\n",
    "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size = 5, stride = 1, padding = 2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # Max Pooling Layer 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Fully connected Layer 1\n",
    "        self.fc1 = nn.Linear(32*7*7, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Convulation Layer 1\n",
    "        x = self.cnn1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        # Max Pooling 1\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        # Convulation Layer 2\n",
    "        x = self.cnn2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        # Max Pooling 2\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        # Resize \n",
    "        out = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully Connected Layer\n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Adım: Model Sınıfını Oluşturma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Adım: Loss Sınıfını Oluşturma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Adım: Optimizer Sınıfını Oluşturma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her iterasyonda modelimizin parametrelerini güncelliyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\theta = \\theta - \\eta \\cdot \\nabla_\\theta $\n",
    "\n",
    "$\\theta$: parameters\n",
    "\n",
    "$\\eta$: learning rate \n",
    "\n",
    "$\\nabla_\\theta$: parameters' gradients\n",
    "\n",
    "\n",
    "parameters = parameters - learning_rate * parameters_gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_Model(\n",
      "  (cnn1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (cnn2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (relu2): ReLU()\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x000002858102F0C8>\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(list(model.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters())[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters())[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 16, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters())[2].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters())[3].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1568])\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters())[4].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters())[5].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Adım: Modelin Eğitilmesi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "İzlenecek adımlar şu şekilde olacaktır.\n",
    "\n",
    "* 1. Input ve labelları değişkenlere dönüştüreceğiz.\n",
    " CNN Input:(1,28,28) ve Feedforward NN Input:(1,28*28)\n",
    " \n",
    "* 2. Gradyanları temizleme\n",
    "\n",
    "* 3. Verilen inpulardan çıktı alma\n",
    "\n",
    "* 4. Loss Hesabı\n",
    "\n",
    "* 5. Gradyan hesaplanması\n",
    "\n",
    "* 6. Gradyanları kullanarak parametreleri güncelleme ( parameters = parameters - learning_rate * parameters_gradients )\n",
    "\n",
    "* 7. Tekrarlama İşlemi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500.  ||   Loss: 0.07009396702051163.  ||  Accuracy: 97\n",
      "Iteration: 1000.  ||   Loss: 0.039620377123355865.  ||  Accuracy: 97\n",
      "Iteration: 1500.  ||   Loss: 0.13273043930530548.  ||  Accuracy: 97\n",
      "Iteration: 2000.  ||   Loss: 0.042526811361312866.  ||  Accuracy: 97\n",
      "Iteration: 2500.  ||   Loss: 0.03482230007648468.  ||  Accuracy: 98\n",
      "Iteration: 3000.  ||   Loss: 0.018919197842478752.  ||  Accuracy: 98\n"
     ]
    }
   ],
   "source": [
    "iteration = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # image yükleme\n",
    "        images = images.requires_grad_()\n",
    "        \n",
    "        # gradyanları sıfırlama\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # ileri yayılım ile çıktı elde etme  \n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Loss Hesaplama: softmax (çapraz entropi kaybı)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # geriye yayılım\n",
    "        loss.backward()\n",
    "        \n",
    "        # parametreleri güncelleme\n",
    "        optimizer.step()\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "        if iteration % 500 == 0:\n",
    "            \n",
    "            # doğruluk hesabı      \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            # test datası boyunca iterasyon yapma\n",
    "            for images, labels in test_loader:\n",
    "                # image yükleme\n",
    "                images = images.requires_grad_()\n",
    "                \n",
    "                # ileri yayılım ile çıktı elde etme  \n",
    "                outputs = model(images)\n",
    "                \n",
    "                # max değeri sağlayan tahmini alma \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # labelların toplam sayısı\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                # toplam doğru tahmin\n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct // total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}.  ||   Loss: {}.  ||  Accuracy: {}'.format(iteration, loss.item(), accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
